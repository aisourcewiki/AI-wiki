<!--
title: Parameters and settings
description: 
published: true
date: 2023-04-15T16:59:03.245Z
tags: 
editor: ckeditor
dateCreated: 2023-04-15T16:45:15.183Z
-->

<h1>Parameters and settings</h1>
<h2>General</h2>
<p><strong>Epochs</strong> - the cycle of examining each of the instance dataset images once (<a href="https://www.reddit.com/r/StableDiffusion/comments/y6gjjz/question_about_training_epochs/">source</a>)</p>
<p><strong>Training steps </strong>-<strong> </strong>the # of steps taken in fine tuning the model. The number of displayed training steps is roughly <strong>(</strong># of images in training set) x (# of epochs) / (batch size). Each batch effectively counts as a single training step (confirm this).&nbsp;</p>
<p><strong>Batch size</strong> - the number of images processed at once during training (<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/4814">source</a>, <a href="https://github.com/victorchall/EveryDream-trainer">source</a>). Increasing speeds up training at the cost of increased VRAM usage.</p>
<p><strong>CFG </strong>- stands for classifier free guidance. Forces the generation to better match the prompt potentially at the cost of image quality or diversity (<a href="https://huggingface.co/blog/stable_diffusion">source</a>)&nbsp;</p>
<p><strong>Sampler</strong> - the method used to estimate noise at each step in the denoising process, which gradually produces a final image from an initial noisy image. There is often a trade-off between speed and accuracy of denoising. (<a href="https://stable-diffusion-art.com/samplers/#What_is_Sampling">source</a>)</p>
<p>&nbsp;</p>
<h2>LoRAs specifically</h2>
<p><strong>LoRA </strong>- stands for low-rank adaptation, a mathematical technique to reduce the number of parameters that are trained. Results in a smaller model which is also faster to train. Technique can be applied to other types of models including LLMs, but has been especially popular for text-to-image models like Stable Diffusion (<a href="https://replicate.com/blog/lora-faster-fine-tuning-of-stable-diffusion">source</a>).</p>
<p><strong>Rank </strong>- rank is the size of the new “smaller” matrix used to store model weights. This is a tunable parameters, which can be increased to store more details but at the expense of larger file size (<a href="https://github.com/microsoft/LoRA">source</a>, for LLMs)</p>
<p><strong>LoHA - </strong>LoRA with Hadamard Product representation (LoHa). A specific type of LoRA which is more parameter efficient (<a href="https://github.com/KohakuBlueleaf/LyCORIS">source</a>, <a href="https://www.reddit.com/r/StableDiffusion/comments/11rbada/what_the_hell_is_a_loconloha_model/">source</a>)<br><br>&nbsp;</p>
