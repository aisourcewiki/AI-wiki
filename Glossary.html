<!--
title: Glossary
description: 
published: true
date: 2023-04-15T21:36:21.839Z
tags: 
editor: ckeditor
dateCreated: 2023-04-15T16:45:06.486Z
-->

<h1>Terms</h1>
<h2>Diffusion models</h2>
<p><strong>Diffusion model</strong> - a type of machine learning model which can produce a final result (e.g. an image) through a step-by-step process of removing noise. In addition to image generation, they can also be used for video generation, audio synthesis, and reinforcement learning (<a href="https://huggingface.co/blog/stable_diffusion">source</a>, <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/diffusers_intro.ipynb">source</a>)&nbsp;</p>
<p><strong>Latent diffusion </strong>- a type of text-to-image model.</p>
<p><strong>VAE</strong> - stands for variational autoencoder and is a component of the “diffusion model”. For model training, used to compress images into the latent space to speed up the training process for the diffusion model. Also used to decode images during inference (<a href="https://jalammar.github.io/illustrated-stable-diffusion/">source</a>, <a href="https://arxiv.org/pdf/2112.10752.pdf">source</a>)</p>
<p><strong>UNet</strong> - a component of the “diffusion model”. Helps to gradually remove noise from the initial noisy image to produce the final output (<a href="https://jalammar.github.io/illustrated-stable-diffusion/">source</a>)</p>
<p><strong>Text encoder</strong> -&nbsp;</p>
<h2>Model training</h2>
<p><strong>Dreambooth - </strong>a method used to fine tune text-to-image models. <strong>(clarify)</strong></p>
<p><strong>EMA </strong>- exponential moving average, a technique used to improve inference performance and reduce the risk of "last-iterations overfitting" by taking the average of weights over a final period. Should be used only for inference, resuming model training (and perhaps fine tuning) should occur on the final (not averaged) weights (<a href="https://www.reddit.com/r/MachineLearning/comments/ucflc2/d_understanding_the_use_of_ema_in_diffusion_models/">source</a>, <a href="https://www.reddit.com/r/StableDiffusion/comments/x5am4v/ema_model_vs_non_ema_differences/">source</a>, <a href="https://huggingface.co/stabilityai/stable-diffusion-2-1/discussions/22">source)</a></p>
<p><strong>Epochs</strong> - the cycle of examining each of the instance dataset images once (<a href="https://www.reddit.com/r/StableDiffusion/comments/y6gjjz/question_about_training_epochs/">source</a>)</p>
<p><strong>Training steps </strong>-<strong> </strong>the # of steps taken in fine tuning the model. The number of displayed training steps is roughly <strong>(</strong># of images in training set) x (# of epochs) / (batch size). Each batch effectively counts as a single training step (confirm this).&nbsp;</p>
<p><strong>Batch size</strong> - the number of images processed at once during training (<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/4814">source</a>, <a href="https://github.com/victorchall/EveryDream-trainer">source</a>). Increasing speeds up training at the cost of increased VRAM usage.</p>
<p><strong>CFG </strong>- stands for classifier free guidance. Forces the generation to better match the prompt potentially at the cost of image quality or diversity (<a href="https://huggingface.co/blog/stable_diffusion">source</a>)&nbsp;</p>
<p><strong>Sampler</strong> - the method used to estimate noise at each step in the denoising process, which gradually produces a final image from an initial noisy image. There is often a trade-off between speed and accuracy of denoising. (<a href="https://stable-diffusion-art.com/samplers/#What_is_Sampling">source</a>)</p>
